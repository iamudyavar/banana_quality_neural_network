{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIV2X5tEhpjZP1uu8m9F/Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamudyavar/banana_quality_neural_network/blob/main/banana_quality_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying the quality of a banana with a neural network\n"
      ],
      "metadata": {
        "id": "FEvwYr_xqWGY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Information:\n",
        "\n",
        "Dependent variables:\n",
        "\n",
        "1. **Size** - size of fruit (continuous)\n",
        "2. **Weight** - weight of fruit (continuous)\n",
        "3. **Sweetness** - sweetness of fruit (continuous)\n",
        "4. **Softness** - softness of fruit (continuous)\n",
        "5. **HarvestTime** - amount of time passed from harvesting of the fruit (continuous)\n",
        "6. **Ripeness** - ripeness of fruit (continuous)\n",
        "7. **Acidity** - acidity of fruit (continuous)\n",
        "\n",
        "\n",
        "Independent variable:\n",
        "1. **Quality** - quality of fruit (Good, Bad)"
      ],
      "metadata": {
        "id": "j-FDh2o3rIov"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "OsKIONpjqM4w",
        "outputId": "0a52f0f8-4b24-4962-ac8b-26547cd53566"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'banana_quality.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-89dd009a71c4>\u001b[0m in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;31m# Fetch dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m \u001b[0mbanana_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"banana_quality.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;31m# Preprocess and clean the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'banana_quality.csv'"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class NeuralNetwork:\n",
        "    # Global variables\n",
        "    weights_input_hidden = weights_hidden_output = None     # Weights\n",
        "    bias_hidden = bias_output = None                        # Biases\n",
        "\n",
        "    # Hyperparameters\n",
        "    activation = None               # Activation function\n",
        "    activation_derivative = None    # Derivative of activation function\n",
        "    learning_rate = 0               # Learning rate\n",
        "    num_epochs = 0                  # Number of epochs\n",
        "    momentum_constant = 0           # Momentum constant\n",
        "\n",
        "    def __init__(self, activation, activation_derivative, learning_rate, num_epochs, momentum_constant):\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = activation_derivative\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_epochs = num_epochs\n",
        "        self.momentum_constant = momentum_constant\n",
        "\n",
        "    def preprocess(self, dataset):\n",
        "        # Encode categorical features\n",
        "        le = LabelEncoder()\n",
        "        categorical_cols = dataset.select_dtypes(include=['object']).columns\n",
        "        for col in categorical_cols:\n",
        "            dataset[col] = le.fit_transform(dataset[col])\n",
        "\n",
        "        # Fill in missing values (if they exist)\n",
        "        dataset = dataset.ffill()\n",
        "\n",
        "        # Split data into X and y\n",
        "        X = dataset.drop('Quality', axis=1)\n",
        "        y = dataset['Quality']\n",
        "\n",
        "        # Split data into train and test sets\n",
        "        return train_test_split(X, y, test_size=0.3)\n",
        "\n",
        "    def train(self, X_train, y_train, input_size, hidden_size, output_size):\n",
        "        # Initialize weights and biases\n",
        "        self.weights_input_hidden = np.random.uniform(-1, 1, (input_size, hidden_size))\n",
        "        self.bias_hidden = np.zeros((1, hidden_size))\n",
        "        self.weights_hidden_output = np.random.uniform(-1, 1, (hidden_size, output_size))\n",
        "        self.bias_output = np.zeros((1, output_size))\n",
        "\n",
        "        # Convert input and target values into an array\n",
        "        inputs = np.array(X_train, dtype=np.float64)\n",
        "        targets = np.array(y_train, dtype=np.int64)\n",
        "\n",
        "        # Start training\n",
        "        hidden_momentum_optimizer = np.zeros((1, hidden_size))\n",
        "        input_momentum_optimizer = np.zeros((hidden_size, input_size))\n",
        "        for epoch in range(self.num_epochs):\n",
        "            for i in range(len(inputs)):\n",
        "                row = inputs[i]\n",
        "                row = np.reshape(row, (input_size,1))\n",
        "\n",
        "                # Forward pass\n",
        "                hidden_outputs, output = self.forward_pass(row)\n",
        "\n",
        "                # Backward pass\n",
        "                hidden_momentum_optimizer, input_momentum_optimizer = self.backward_pass(targets[i], output, hidden_outputs, row, hidden_momentum_optimizer, input_momentum_optimizer)\n",
        "\n",
        "        # Return training accuracy\n",
        "        return self.get_accuracy_score(inputs, targets)\n",
        "\n",
        "    def test(self, X_test, y_test):\n",
        "        # Convert input and target values into an array\n",
        "        inputs = np.array(X_test, dtype=np.float64)\n",
        "        targets = np.array(y_test, dtype=np.float64)\n",
        "\n",
        "        # Return testing accuracy\n",
        "        return self.get_accuracy_score(inputs, targets)\n",
        "\n",
        "    def forward_pass(self, input):\n",
        "        # Hidden layer calculations\n",
        "        hidden_inputs = np.dot(input.T, self.weights_input_hidden) + self.bias_hidden\n",
        "        hidden_outputs = self.activation(hidden_inputs)\n",
        "\n",
        "        # Output layer calculations\n",
        "        output_inputs = np.dot(hidden_outputs, self.weights_hidden_output) + self.bias_output\n",
        "        output = self.activation(output_inputs)\n",
        "        return (hidden_outputs, output)\n",
        "\n",
        "    def backward_pass(self, target_value, final_output, hidden_outputs, data_row, hidden_momentum_optimizer, input_momentum_optimizer):\n",
        "        # Update weights between hidden and output layer\n",
        "        output_delta = np.dot((target_value - final_output), self.activation_derivative(final_output))\n",
        "        hidden_output_weightchange = self.learning_rate * np.dot(output_delta, hidden_outputs)\n",
        "        hidden_momentum_optimizer = self.momentum_constant * hidden_momentum_optimizer + hidden_output_weightchange\n",
        "        self.weights_hidden_output += hidden_momentum_optimizer.T\n",
        "\n",
        "        # Update weights between input and hidden layer\n",
        "        helper_output_delta = np.broadcast_to(output_delta, (4, 1))\n",
        "        activation_on_hidden_output = self.activation_derivative(hidden_outputs)\n",
        "        hidden_deltas = np.dot(np.dot(self.weights_hidden_output, activation_on_hidden_output), helper_output_delta)\n",
        "        input_hidden_weightchange = self.learning_rate * np.dot(hidden_deltas, data_row.T)\n",
        "        input_momentum_optimizer = self.momentum_constant * input_momentum_optimizer + input_hidden_weightchange\n",
        "        self.weights_input_hidden += input_momentum_optimizer.T\n",
        "\n",
        "        return (hidden_momentum_optimizer, input_momentum_optimizer)\n",
        "\n",
        "    def get_accuracy_score(self, inputs, targets):\n",
        "        predicted_outputs = []\n",
        "\n",
        "        # Run forward passes to make our prediction\n",
        "        for i in range(len(inputs)):\n",
        "            row = inputs[i]\n",
        "            row = np.reshape(row, (len(inputs[i]), 1))\n",
        "            output = self.forward_pass(row)[1]\n",
        "            predicted_outputs.append(output[0][0])\n",
        "\n",
        "        predicted_outputs = np.round(predicted_outputs).astype(int)\n",
        "        return accuracy_score(predicted_outputs, targets)\n",
        "\n",
        "\n",
        "# Declare activation function\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x) * sigmoid(1 - x)\n",
        "\n",
        "def tanh(x):\n",
        "  return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - tanh(x)**2\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return np.array(x > 0).astype('int')\n",
        "\n",
        "# Initialize model\n",
        "model = NeuralNetwork(activation=sigmoid, activation_derivative=sigmoid_derivative, learning_rate=0.03, num_epochs=100, momentum_constant=0.9)\n",
        "\n",
        "# Fetch dataset\n",
        "banana_dataset = pd.read_csv(\"banana_quality.csv\")\n",
        "\n",
        "# Preprocess and clean the data\n",
        "X_train, X_test, y_train, y_test = model.preprocess(banana_dataset)\n",
        "\n",
        "# Train\n",
        "train_accuracy = model.train(X_train, y_train, 7, 4, 1)\n",
        "\n",
        "# Test\n",
        "test_accuracy = model.test(X_test, y_test)\n",
        "\n",
        "# Print results\n",
        "print(f'Training accuracy: {train_accuracy}')\n",
        "print(f'Testing accuracy: {test_accuracy}')"
      ]
    }
  ]
}