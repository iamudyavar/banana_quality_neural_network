{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamudyavar/banana_quality_neural_network/blob/main/banana_quality_neural_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEvwYr_xqWGY"
      },
      "source": [
        "# Identifying the quality of a banana with a neural network\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-FDh2o3rIov"
      },
      "source": [
        "## Dataset Information:\n",
        "\n",
        "Kaggle link: https://www.kaggle.com/datasets/l3llff/banana\n",
        "\n",
        "Dependent variables:\n",
        "\n",
        "1. **Size** - size of fruit (continuous)\n",
        "2. **Weight** - weight of fruit (continuous)\n",
        "3. **Sweetness** - sweetness of fruit (continuous)\n",
        "4. **Softness** - softness of fruit (continuous)\n",
        "5. **HarvestTime** - amount of time passed from harvesting of the fruit (continuous)\n",
        "6. **Ripeness** - ripeness of fruit (continuous)\n",
        "7. **Acidity** - acidity of fruit (continuous)\n",
        "\n",
        "\n",
        "Independent variable:\n",
        "1. **Quality** - quality of fruit (Good, Bad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0cnaa0RUW5z",
        "outputId": "cad06aa9-0683-4e35-ceb0-59d78947944d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.82125\n",
            "Testing accuracy: 0.82625\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#Declare activation function and derivatives. We will use these as inputs to model\n",
        "def sigmoid(x):\n",
        "  return 1/(1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "  return sigmoid(x)*sigmoid(1 - x)\n",
        "\n",
        "def tanh(x):\n",
        "  return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
        "\n",
        "def tanh_derivative(x):\n",
        "  return 1 - tanh(x)**2\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "  return np.array(x > 0).astype('int')\n",
        "\n",
        "\n",
        "class NeuralNetwork:\n",
        "  #Declaring weights from input to hidden layer and hidden to output\n",
        "  wih=None\n",
        "  who=None\n",
        "  hiddenBias=None\n",
        "  outputBias=None\n",
        "\n",
        "  #Hyperparameters\n",
        "  activation=None\n",
        "  activation_der=None\n",
        "  learningRate=None\n",
        "  epochs=0\n",
        "  momentumConst=0\n",
        "\n",
        "  def __init__(self,activation,activation_der,learningRate,epochs,momentumConst):\n",
        "    self.name=activation\n",
        "    self.activation=activation\n",
        "    self.activation_der=activation_der\n",
        "    self.learningRate=learningRate\n",
        "    self.epochs=epochs\n",
        "    self.momentumConst=momentumConst\n",
        "\n",
        "  def preprocess(self,dataset):\n",
        "    #Encoding the dataset\n",
        "    le=LabelEncoder()\n",
        "    cat=dataset.select_dtypes(include=['object']).columns\n",
        "    for col in cat:\n",
        "      dataset[col]=le.fit_transform(dataset[col])\n",
        "\n",
        "    dataset = dataset.ffill()\n",
        "    X = dataset.drop('Quality', axis=1)\n",
        "    y = dataset['Quality']\n",
        "\n",
        "    return train_test_split(X,y,test_size=0.3)#,random_state=42)\n",
        "\n",
        "  def train(self,X_train,y_train, inputSize ,hiddenSize, outputSize):\n",
        "    #Initializing weights with values between -1 and 1 and bias with 0\n",
        "    self.wih=np.random.uniform(-1,1,(inputSize,hiddenSize))\n",
        "    self.hiddenBias=np.zeros((1,hiddenSize))\n",
        "    self.who=np.random.uniform(-1,1,(hiddenSize,outputSize))\n",
        "    self.outputBias=np.zeros((1,outputSize))\n",
        "\n",
        "    #Temp variables to hold X_train and Y_train\n",
        "    instances=np.array(X_train,dtype=np.float64)\n",
        "    target=np.array(y_train,dtype=np.float64)\n",
        "\n",
        "    #Optimizer intialization\n",
        "    hidMomOpt=np.zeros((1,hiddenSize))\n",
        "    inpMomOpt=np.zeros((hiddenSize,inputSize))\n",
        "\n",
        "    #Looping over all inputs i.e. a forward pass and backward pass over every instance for specified epochs\n",
        "    for e in range((self.epochs)):\n",
        "      for i in range(len(instances)):\n",
        "        row=instances[i]\n",
        "        row=np.reshape(row,(inputSize,1))\n",
        "\n",
        "        #forward pass\n",
        "        ho,output=self.forwardPass(row)\n",
        "\n",
        "        #backward pass\n",
        "        hidMomOpt,momOpt=self.backwardPass(target[i],output,ho,row, hidMomOpt,inpMomOpt)\n",
        "\n",
        "    #Training accuracy\n",
        "    #Array to store training predictions\n",
        "    p=[]\n",
        "\n",
        "    for i in range(len(instances)):\n",
        "      r=instances[i]\n",
        "      r=np.reshape(r,(len(instances[i]),1))\n",
        "\n",
        "      o=self.forwardPass(r)[1]\n",
        "      p.append(o[0][0])\n",
        "\n",
        "    p= np.round(p).astype(int)\n",
        "\n",
        "    #Returning accuracy using scikit's accuracy_score\n",
        "    return accuracy_score(p,target)\n",
        "\n",
        "  def test(self,X_test,y_test):\n",
        "\n",
        "    testX=np.array(X_test,dtype=np.float64)\n",
        "    testY=np.array(y_test,dtype=np.float64)\n",
        "\n",
        "    #Testing accuracy\n",
        "    #Storing testing predictions\n",
        "    predictions=[]\n",
        "\n",
        "    for i in range(len(testX)):\n",
        "      row=testX[i]\n",
        "      row=np.reshape(row,(len(testX[i]),1))\n",
        "\n",
        "      output=self.forwardPass(row)[1]\n",
        "      predictions.append(output[0][0])\n",
        "\n",
        "    predictions= np.round(predictions).astype(int)\n",
        "\n",
        "    #Returning test accuracy\n",
        "    return accuracy_score(predictions,testY)\n",
        "\n",
        "  def forwardPass(self,input):\n",
        "    #netIn=input\n",
        "    hi=np.dot(input.T,self.wih)+self.hiddenBias\n",
        "\n",
        "    #xh=sig(netIn)\n",
        "    ho=self.activation(hi)\n",
        "\n",
        "    #xO=sig(net(xh))\n",
        "    oinput=np.dot(ho,self.who)+self.outputBias\n",
        "    output=self.activation(oinput)\n",
        "    return (ho,output) #Made change from (ho,output)\n",
        "\n",
        "  def backwardPass(self,target,output,ho,row,hidMomOpt,inpMomOpt):\n",
        "    #Delta of output\n",
        "    outputDel=np.dot((target-output),self.activation_der(output))\n",
        "\n",
        "    #Change in weight\n",
        "    hoWeightChange=self.learningRate*np.dot(outputDel,ho)\n",
        "    hidMomOpt=self.momentumConst*hidMomOpt+hoWeightChange\n",
        "\n",
        "    #Update\n",
        "    self.who+=hidMomOpt.T\n",
        "\n",
        "    #Output Bias update\n",
        "    self.outputBias +=self.learningRate*outputDel\n",
        "\n",
        "    #Reshape for calculation purposes\n",
        "    helper=np.broadcast_to(outputDel,(4,1))\n",
        "\n",
        "    #Delta of hidden nodes\n",
        "    hoDer=self.activation_der(ho)\n",
        "    hidDel=np.dot(np.dot(self.who,hoDer),helper)\n",
        "\n",
        "    #Change in weight\n",
        "    ihWeightChange=self.learningRate*np.dot(hidDel,row.T)\n",
        "    inpMomOpt=self.momentumConst*inpMomOpt+ihWeightChange\n",
        "\n",
        "    #Update\n",
        "    self.wih+=inpMomOpt.T\n",
        "\n",
        "    #Reshape hidden gradient\n",
        "    hidDelTemp = hidDel.reshape(1, -1)\n",
        "    #Hidden bias update\n",
        "\n",
        "    self.hiddenBias+=self.learningRate*hidDelTemp\n",
        "\n",
        "    return (hidMomOpt,inpMomOpt)\n",
        "\n",
        "#Initialize model\n",
        "model = NeuralNetwork(activation=sigmoid,activation_der=sigmoid_derivative,learningRate=0.03, epochs=100, momentumConst=0.9)\n",
        "\n",
        "#Fetch dataset\n",
        "banana_dataset = pd.read_csv(\"https://raw.githubusercontent.com/iamudyavar/banana_quality_neural_network/main/banana_quality.csv\")\n",
        "\n",
        "#Preprocess and clean the data\n",
        "X_train, X_test, y_train, y_test = model.preprocess(banana_dataset)\n",
        "\n",
        "train_accuracy = model.train(X_train, y_train, 7, 4, 1)\n",
        "\n",
        "#Test\n",
        "test_accuracy = model.test(X_test, y_test)\n",
        "\n",
        "#Print results\n",
        "print(f'Training accuracy: {train_accuracy}')\n",
        "print(f'Testing accuracy: {test_accuracy}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}